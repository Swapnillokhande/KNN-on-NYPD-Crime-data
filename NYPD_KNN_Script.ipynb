{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to calculate the Euclidean Distance\n",
    "\n",
    "import math \n",
    "def euclideandistance(instance1,instance2,length):\n",
    "    distance=0\n",
    "    for x in range(1,length):\n",
    "        #print(instance1[x],instance2[x])\n",
    "        distance+=pow((instance1[x]-instance2[x]),2)\n",
    "        #print(distance)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to find the neighbourhood\n",
    "import operator\n",
    "\n",
    "def getneighborhood(trainingdata,testinstance,k):\n",
    "    distance=[]\n",
    "    length=len(testinstance)\n",
    "    #print(\"Length of testinstance:\",length)\n",
    "    #print(\"Length trainingSet\",len(trainingdata))\n",
    "    for x in range(len(trainingdata)):\n",
    "        dist=euclideandistance(trainingdata[x],testinstance,length)\n",
    "        distance.append((trainingdata[x],dist))\n",
    "    \n",
    "    distance.sort(key=operator.itemgetter(1))\n",
    "    neighbor=[]\n",
    "    #print(distance)\n",
    "    for x in range(k):\n",
    "        neighbor.append(distance[x][0])\n",
    "    #print(\"Neighbors of the test instance\",neighbor)\n",
    "    return neighbor\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to get the output class from the neighbors\n",
    "import operator\n",
    "\n",
    "def getoutputclass(neighbors):\n",
    "    outputclass={}\n",
    "    for x in range(len(neighbors)):\n",
    "        response=neighbors[x][0]\n",
    "        if response in outputclass:\n",
    "            outputclass[response]+=1\n",
    "        else:\n",
    "            outputclass[response]=1\n",
    "    sortedclass=sorted(outputclass.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    #print(\"Class for the test instance\",outputclass.items())\n",
    "    return sortedclass[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getaccuracy(testinstance, prediction):\n",
    "    correct=0\n",
    "#     print(\"Test instance in Accuracy\",testinstance)\n",
    "#     print(\"Test instance 19\",testinstance[19])\n",
    "#     print(\"Prediction\",prediction)\n",
    "    for x in range(len(testinstance)):\n",
    "        if testinstance[x][0] == prediction[x]:\n",
    "            correct+=1\n",
    "            #print(correct)\n",
    "    return (correct/len(testinstance))*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split the dataset into train and test\n",
    "\n",
    "def splitdataset(dataset,trainingdata=[], testdata=[]):\n",
    "    for x in range(len(dataset)):\n",
    "        if x<int(len(dataset)*0.8):\n",
    "            trainingdata.append(dataset[x])\n",
    "        else:\n",
    "            testdata.append(dataset[x])\n",
    "    #print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data dimensions: 8000 , 162\n",
      "Test Data: 2000 , 162\n",
      "Predicted Crimes for the test dataset: ['MISDEMEANOR', 'MISDEMEANOR', 'MISDEMEANOR', 'FELONY', 'MISDEMEANOR', 'FELONY', 'MISDEMEANOR', 'FELONY', 'MISDEMEANOR', 'FELONY']\n",
      "Accuracy of the KNN model: 87.85\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    #define variables and other parameters\n",
    "    \n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    dataSet=[]\n",
    "    data=open(\"D:\\\\NEU Courses\\\\Predictive Anaytics\\\\Final Project\\\\NYPD_Complaint_Data_Historic.csv\",'r')\n",
    "\n",
    "    df_data=pd.read_csv(data)\n",
    "\n",
    "    #select only the relevant columns\n",
    "    \n",
    "    cols_mode = ['OFNS_DESC', 'CRM_ATPT_CPTD_CD', 'LAW_CAT_CD', 'BORO_NM', \n",
    "                 'LOC_OF_OCCUR_DESC', 'JURIS_DESC', 'PREM_TYP_DESC', 'SUSP_RACE', 'SUSP_SEX', 'VIC_RACE', 'VIC_SEX']\n",
    "\n",
    "    updated_df_train=df_data[cols_mode]\n",
    "    \n",
    "    #check for missing values and replace by most frequent\n",
    "    for col in cols_mode: \n",
    "        updated_df_train[col].fillna(updated_df_train[col].value_counts().idxmax(), inplace=True)\n",
    "    \n",
    "    \n",
    "    #randomly select rows from the dataset\n",
    "    subset_indices = np.random.randint(low=0, high=len(updated_df_train), size=10000)\n",
    "    selected_df_train = updated_df_train.iloc[subset_indices]\n",
    "    \n",
    "    #create dummy variables\n",
    "    dummy_df=pd.get_dummies(selected_df_train, columns=['OFNS_DESC', 'CRM_ATPT_CPTD_CD', 'BORO_NM', 'LOC_OF_OCCUR_DESC',\n",
    "                                                       'JURIS_DESC', 'PREM_TYP_DESC', 'SUSP_RACE', 'SUSP_SEX', \n",
    "                                                       'VIC_RACE', 'VIC_SEX'])\n",
    "\n",
    "\n",
    "    #add rows in a list and split train and test dataset\n",
    "    \n",
    "    for x in subset_indices:\n",
    "        a=list(dummy_df.loc[x])\n",
    "        dataSet.append(a)\n",
    "        \n",
    "        \n",
    "    #convert the data elements (except Crime label - target variable) into float type \n",
    "    for i in range(len(dataSet)):\n",
    "        a=dataSet[i]\n",
    "        for j in range(1,len(a)):\n",
    "            #print(i,j)\n",
    "            if (type(a[j])==str):\n",
    "                a[j]=0.0\n",
    "            else:\n",
    "                b=a[j].astype(float)\n",
    "                dataSet[i][j]=b\n",
    "            \n",
    "    #print(len(dataSet))\n",
    "    splitdataset(dataSet,trainingSet,testSet)\n",
    "    print(\"Training Data dimensions:\",len(trainingSet),\",\",len(trainingSet[0]))\n",
    "    print(\"Test Data:\",len(testSet),\",\",len(testSet[0]))\n",
    "#     print(\"Sample Training Set:\",trainingSet[0:5])\n",
    "#     print(\"Sample Test Set:\",testSet[0:5])\n",
    "    \n",
    "    #call functions for each test row and classify the output\n",
    "    #generate output\n",
    "    prediction=[]\n",
    "    k=5\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors=getneighborhood(trainingSet,testSet[x],k)\n",
    "        #print(neighbors)\n",
    "        response=getoutputclass(neighbors)\n",
    "        #print(response)\n",
    "        prediction.append(response)\n",
    "        #print(\"Predicted:\",response,\"Actual:\",testSet[x][-1])\n",
    "    print(\"Predicted Crimes for the test dataset:\",prediction[:10])\n",
    "    accuracy=getaccuracy(testSet,prediction)\n",
    "    print(\"Accuracy of the KNN model:\",accuracy)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
